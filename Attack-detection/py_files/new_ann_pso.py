# -*- coding: utf-8 -*-
"""new_ANN_PSO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qSFEqX8GOmfI5hbfmDlGO0ouRs2dHQ_-
"""

import numpy as np;
import numpy.random;
import sklearn.metrics;
import math;

class NeuralNetwork:
    def __init__(self, nodes, weights=None):
        self.nodes = nodes;
        if weights==None:
            self.weights=[];
            for i in range(0,len(nodes)-1):
                self.weights.append(np.random.uniform(size=(nodes[i]+1, nodes[i+1])).tolist());
            self.weights = self.weights;
        else:
            self.weights = weights;
        print(self.weights[0][0][0]);
            
    def propagate(self, input_data):
        level = np.array(input_data).T.tolist();
        
        for i in range(0, len(self.nodes)-1):
          level1=[];
          prev_level = np.insert(np.array(level), 0, 1, 0).tolist();
          for j in range(0, self.nodes[i+1]):
            hypo = 0;
            for k in range(0, len(prev_level)):
              hypo = hypo + self.weights[i][j][k] * prev_level[k];
            level1.append(1/(1+math.exp(-hypo)));
          level = level1.copy();
        return level;
    
    def setData(self, total_input_data, total_output_data):
        self.ip = total_input_data;
        self.op = total_output_data;
    
    def cost(self):
        cost_val = 0;
        for i in range(0, len(self.ip)):
            exp_output = self.propagate(self.ip[i]);
            cost_val = cost_val + sklearn.metrics.mean_squared_error(self.ip[i], exp_output);
        return cost_val;
    
    def setPosition(self, pos):
        p = 0;
        for i in range(0, len(nodes)-1):
            for j in range(0, nodes[i]+1):
                for k in range(0, nodes[i+1]):
                    self.weights[i][j][k] = pos[p].copy();
                    p=p+1;
        
    
    def getPosition(self):
        pos = [];
        for i in range(0, len(nodes)-1):
            for j in range(0, nodes[i]+1):
                for k in range(0, nodes[i+1]):
                    pos.append(self.weights[i][j][k]);
        
        return pos;

import numpy as np
import numpy.random

class ParticleSwarmOptimiser:
    def __init__(self, n_net, ip, op, chi=0.73, p_phi=2, g_phi=2):
        self.n_net = n_net;
        
        self.chi = chi;
        self.p_phi = p_phi;
        self.g_phi = g_phi;
        
        self.popn = len(self.n_net);
        self.dim = len(self.n_net[0]);
        
        self.pos = [];
        for i in range(0, len(n_net)):
            self.pos.append(np.array(n_net[i].getPosition()));
        self.pos = np.array(self.pos);
        
        self.vel = np.random.uniform(size=(len(n_net), len(n_net[0].getPosition())));
        
        self.p_best = self.pos.copy();
        
        self.fit=[];
        for i in range(0, len(n_net)):
            self.fit.append(n_net[i].cost());
            
        self.g_best = self.p_best[self.fit.argmin()];
        self.best_fit = self.fit.min();
        
        
    def swarm_improve(self):
        p_random = np.random.uniform(size=(self.popn, self.dim));
        g_random = np.random.uniform(size=(self.popn, self.dim));
        
        self.vel = self.chi * (self.vel + self.p_phi * p_random * (self.p_best - self.pos)\
                               + self.g_phi * g_random * (self.g_best - self.pos));
        
        self.pos = self.pos + self.vel;
        
        nn = [];
        
        for i in range(0, len(n_net)):
            nn.append(NeuralNetwork(n_net[0].nodes));
            nn[i].setData(ip, op);
            nn[i].setPosition(self.pos[i].tolist());
            
        de = DifferentialEvolution(nn);
        nn = de.optimise();
            
        for i in range(0, len(n_net)):
            curr_fit = nn[i].cost();
            if cuur_fit < self.fit[i]:
                self.p_best[i] = self.pos[i].copy();
                self.fit[i] = curr_fit;
            
        self.g_best = self.p_best[self.fit.argmin()].copy();
        self.best_fit = self.fit.min();
    
    def optimise(self, tol=0.0001, max_iter=500):
        iterate = 0;
        while self.best_fit > tol and iterate < max_iter:
            self.swarm_improve();
            iterate = iterate + 1;

import numpy as np;
import numpy.random;
import random;

class DifferentialEvolution:
  def __init__(self, n_net, cr=0.15, mut=0.2):
    self.cr = cr;
    self.n_net = n_net;
    self.mut = mut;
    
    self.upp_val = np.zeros(shape=len(n_net[0])).tolist();
    self.low_val = self.upp_val.copy();
    
    for i in range(0, len(n_net[0])):
      self.upp_val[i] = float('-inf');
      self.low_val[i] = float('inf');
      for j in range(0, len(n_net)):
        if self.upp_val[i] < self.n_net[j][i]:
          self.upp_val[i] = self.n_net[j][i];
        if self.low_val[i] > self.n_net[j][i]:
          self.low_val[i] = self.n_net[j][i];
          
    
  def mutation():
    
    mut_gen = [];
    
    for i in range(0, len(self.n_net)):
      curr_part = self.n_net.pop(i);
      
      random_part = np.array(random.sample(self.n_net, 3));
      for j in range(0,3):
        random_part[j] = np.array(random_part[j].getPosition());
        
      self.n_net.insert(i, curr_part);
      
      mut_gen.append((random_part[0]+mut*(random_part[1] - random_part[2])).tolist());
    
    return mut_gen;
  
    
  def recombination(mut_gen):
    
    next_gen = [];
    
    for i in range(0, len(self.n_net)):
      next_gen_param = [];
      rand_i = random.randint(1, len(self.n_net[i]));
      
      for j in range(0, len(self.n_net[i])):
        if random.randint(0,1)<=self.cr or j == rand_i:
          next_jen_param.append(mut_gen[i][j]);
        else
          next_gen_param.append(self.n_net[i][j]);
          
      next_gen.append(next_gen_param);
      
    return next_gen;
  
    
  def selection(next_gen):
    final_gen = [];
    new_gen = NeuralNetwork(n_net.nodes);
    for i in range(0, len(self.n_net)):
      new_gen.setPosition(next_gen[i]);
      
      if new_gen.cost < self.n_net[i].cost:
        final_gen.append(new_gen);
      else
        final_gen.append(self.n_net[i]);
    
    return final_gen;
    
  def optimise(self):
    mut_gen = mutation();
    next_gen = recombination(mut_gen);
    return selection(next_gen);

if __name__ == '__main__':
    
    import csv;
    import numpy as np;
    import sklearn.metrics;
    from sklearn.model_selection import train_test_split;
    
    file_d = open('new_dataset.csv', 'r');
    readl = csv.reader(file_d);
    
    data = []; target = [];
    
    for row in readl:
        data.append(row[0:-1]);
        target.append(row[-1]);

    train_in, test_in, train_out, test_out = sklearn.model_selection.train_test_split(data, target);
    
    popn = 100;
    
    n_net_pop = [];
    
    nodes = [len(train_in[0]), 8, 4, 1];
    
    for i in range(0, popn):
        nn = NeuralNetwork(nodes);
        nn.setData(train_in, train_out);
        n_net_pop.append(nn);
    
    pso = ParticleSwarmOptimiser(n_net_pop);
    
    i=0;
    best_val = [[i, pso.best_fit]];
    print([i,pso.best_fit]);
    while i < 500 and pso.best_fit > 1e-6:
        pso.optimise();
        i=i+1;
        if pso.best_fit < best_val[-1][1]:
            best_val.append([i, pso.best_fit]);
            print([i, pso.best_fit]);
    
    best_weight = pso.g_best;
    best_nn = NeuralNetwork(nodes);
    best_nn.setWeights(best_weight);
    
    predict_out = [];
    for i in range(0, len(test_out)):
        predict_out.append(best_nn.propagate(test_in[i]));
    
    print (sklearn.metrics.classification_report(test_out, predict_out));