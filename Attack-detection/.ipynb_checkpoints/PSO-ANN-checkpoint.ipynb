{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "class ParticleSwarmOptimiser:\n",
    "    def __init__(self, cost, dimen, popn=50, chi=0.73, p_phi=2, g_phi=2):\n",
    "        #Iniialising the optimiser\n",
    "        self.cost = cost;\n",
    "        self.dim = dimen;\n",
    "        self.popn = popn;\n",
    "        self.chi = chi;\n",
    "        self.p_phi = p_phi;\n",
    "        self.g_phi = g_phi;\n",
    "        \n",
    "        #Initialising the position and velocity of particles\n",
    "        self.pos = np.random.uniform(size=(self.popn, self.dim));\n",
    "        self.vel = np.random.uniform(size=(self.popn, self.dim));\n",
    "        \n",
    "        #Setting the particle best and global best of the population\n",
    "        self.p_best = self.pos.copy();\n",
    "        self.fit = self.cost(self.pos);\n",
    "        self.g_best = self.p_best[self.fit.argmax()];\n",
    "        self.best_fit = self.fit.min();\n",
    "    \n",
    "    def swarm_improve(self):\n",
    "        #Updating the velocities of particles\n",
    "        p_random = np.random.uniform(size=(self.popn, self.dim));\n",
    "        g_random = np.random.uniform(size=(self.popn, self.dim));\n",
    "        \n",
    "        self.vel = self.chi * (self.vel + self.p_phi * p_random * (self.p_best - self.pos)\\\n",
    "                               + self.g_phi * g_random * (self.g_best - self.pos));\n",
    "        \n",
    "        #Updating the positions of the particles\n",
    "        self.pos = self.pos + self.vel;\n",
    "        \n",
    "        #Updating the particle best and global best values\n",
    "        curr_fit = self.cost(self.pos);\n",
    "        \n",
    "        self.p_best[curr_fit < self.fit] = self.pos[curr_fit < self.fit];\n",
    "        self.fit[curr_fit < self.fit] = self.curr_fit[curr_fit < self.fit];\n",
    "        \n",
    "        self.g_best = self.p_best[self.fit.argmax()];\n",
    "        self.best_fit = self.fit.min();\n",
    "    \n",
    "    def optimise(self, tol=0.00001, max_iter=200):\n",
    "        iterate = 0;\n",
    "        while self.best_fit > tol and iterate < max_iter:\n",
    "            self.swarm_improve();\n",
    "            iterate = iterate + 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, nodes, weights=None):\n",
    "        self.nodes = nodes;\n",
    "        \n",
    "        if self.weights == None:\n",
    "            self.weights = [];\n",
    "            for i in range(0, len(self.nodes)-1):\n",
    "                self.weights.append(np.random.uniform(size=(self.nodes[i]+1, self.nodes[i+1])));\n",
    "        else:\n",
    "            self.weights = weights;\n",
    "    \n",
    "    def propagate(self, data_in):\n",
    "        level = data_in.T;\n",
    "        \n",
    "        for i in range(0, len(self.nodes)-1):\n",
    "            hypo = np.dot(self.weights[i], np.insert(level, 0, 1, 0));\n",
    "            level = 1/(1+np.exp(-hypo));\n",
    "        return level;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0fae3b34a0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'01.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mread_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '01.csv'"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv;\n",
    "\n",
    "dataset = open('01.csv', 'r');\n",
    "read_file = csv.reader(dataset);\n",
    "\n",
    "features = [];\n",
    "output = [];\n",
    "\n",
    "for row in read_file:\n",
    "    features.append(row[0:-1]);\n",
    "    output.append(row[-1]);\n",
    "\n",
    "train_in, test_in, train_out, test_out = sklearn.model_selection.train_test_split(features, output);\n",
    "\n",
    "train_in = np.asarray(train_in);\n",
    "train_out = np.asarray(train_out);\n",
    "test_out = np.asarray(test_out);\n",
    "test_in = np.asarray(test_in);\n",
    "\n",
    "input_no = train_in.size[1];\n",
    "print(input_no);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '2' '3']\n",
      " ['5' '6' '7']\n",
      " ['9' '10' '11']\n",
      " ['13' '14' '15']\n",
      " ['17' '18' '19']\n",
      " ['21' '22' '23']\n",
      " ['25' '26' '27']]\n",
      "(7, 3)\n"
     ]
    }
   ],
   "source": [
    "import csv;\n",
    "import numpy as np;\n",
    "\n",
    "file_d = open('01.csv', 'r');\n",
    "readl = csv.reader(file_d);\n",
    "\n",
    "data = [];\n",
    "target = [];\n",
    "\n",
    "for row in readl:\n",
    "    data.append(row[0:-1]);\n",
    "    target.append(row[-1]);\n",
    "\n",
    "data = np.asarray(data);\n",
    "print(data);\n",
    "print(data.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
